{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Testing and CI\n",
    "\n",
    "**Version 0.1**\n",
    "\n",
    "The notebook contains problems about code testing and continuous integration.\n",
    "\n",
    "* * *\n",
    "\n",
    "E Tollerud (STScI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Set up py.test in you repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem we'll aim to get the [py.test](https://docs.pytest.org/en/latest/) testing framework up and running in the code repository you set up in the last set of problems.  We can then use it to collect and run tests of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a: Ensure py.test is installed\n",
    "\n",
    "Of course ``py.test`` must actually be installed before you can use it. The commands below should work for the Anaconda Python Distribution, but if you have some other Python installation you'll want to install `pytest` (and its coverage plugin) as directed in the install instructions for ``py.test``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!conda install pytest pytest-cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b: Ensure your repo has code suitable for unit tests\n",
    "\n",
    "Depending on what your code actually does, you might need to modify it to actually perform something testable.  For example, if all it does is print something, you might find it difficult to write an effective unit test.  Try adding a function that actually performs some operation and returns something different depending on various inputs.  That tends to be the easiest function to unit-test: one with a clear \"right\" answer in certain situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also be sure you have `cd`ed to the *root* of the repo for `pytest` to operate correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c: Add a test file with a test function\n",
    "\n",
    "The test must be part of the package and follow the convention that the file and the function begin with ``test`` to get picked up by the test collection machinery.  Inside the test function, you'll need some code that fails if the test condition fails.  The easiest way to do this is with an ``assert`` statement, which raises an error if its first argument is False.\n",
    "\n",
    "*Hint: remember that to be a valid python package, a directory must have an ``__init__.py``*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir #complete\n",
    "!touch #complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%file <yourpackage>/tests/test_something.py\n",
    "\n",
    "def test_something():\n",
    "    assert #complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d: Run the tests\n",
    "\n",
    "Once you have an example test, you can try invoking ``py.test``.  This should yield a report that shows a dot for each test. If all you see are dots, the tests ran sucessfully.  But if there's a failure, you'll see the error, and the traceback showing where the error happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!py.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1e: Check coverage\n",
    "\n",
    "The coverage plugin we installed will let you check which lines of your code are actually run by the testing suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!py.test --cov=<yourproject> tests/ #complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should yield a report, which you can use to decide if you need to add more tests to acheive complete coverage.  Check out the command line arguments to see if you can get a more detailed line-by-line report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Implement some unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sub-problems below each contain somewhat different unit testing challenges.  Place the code from the snippets in your repository by default, the below will place them in distinct files), and write tests to ensure the correctness of the functions.  Try to achieve 100% coverage for all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a\n",
    "\n",
    "*Hint: hint*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b\n",
    "\n",
    "*Hint: numpy has some usful functions for \"nearly equal\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c\n",
    "\n",
    "*Hint: hint*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d\n",
    "\n",
    "*Hint: hint*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Set up travis to run your tests whenever a change is made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a testing suite set up, you can try to turn on a continuous integration service to constantly check that any update you might send doesn't create a bug.  We will the [Travis-CI](https://travis-ci.org/) service for this purpose, as it has one of the lowest barriers to entry from Github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a: Ensure the test suite is passing locally\n",
    "\n",
    "Seems obvious, but it's easy to forget to check this and only later realize that all the trouble you thought you had setting up the CI service was because the tests were actually broken..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!py.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b: Set up an account on travis\n",
    "\n",
    "This turns out to be quite convenient.  If you go to the [Travis web site](https://travis-ci.org/), you'll see a \"Sign in with GitHub\" button.  You'll need to authorize Travis, but once you've done so it will automatically log you in and know which repositories are yours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c: Create a minimal ``.travis.yml`` file.\n",
    "\n",
    "Before we can activate travis on our repo, we need to tell travis a variety of metadata about what's in the repository and how to run it.  The template below should be sufficient for the simplest needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%file .travis.yml\n",
    "\n",
    "language: python\n",
    "python:\n",
    "  - \"3.6\"\n",
    "# command to install dependencies\n",
    "#install: \"pip install numpy\"  #uncomment this if your code depends on numpy or similar\n",
    "# command to run tests\n",
    "script: pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to commit and push this to github before proceeding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!git #complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d: activate Travis\n",
    "\n",
    "You can now click on your profile picture in the upper-right and choose \"accounts\".  You should see your repo listed there, presumably with a grey X next to it.  Click on the X, which should slide the button over and therefore activate travis on that repository. Once you've done this, you should be able to click on the name of the reposository in the travis accounts dashboard, popping up a window showing the build already in progress (if not, just be a bit patient)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Wait for the tests to complete.  If all is good you should see a green check next to the repository name.  Otherwise you'll need to go in and fix it and the tests will automatically trigger when you send a new update."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3e: Break the build\n",
    "\n",
    "Make a small change to the repository to break a test.  If all else fails simply add the following test:\n",
    "\n",
    "```\n",
    "def test_fail():\n",
    "    assert False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Push that change up and go look at travis.  It should automatically run the tests and result in them failing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3f: Have your neighbor fix your repo\n",
    "\n",
    "Challenge your nieghbor to find the bug and fix it.  Have them follow the Pull Request workflow, but do *not* merge the PR until Travis' tests have finished (they *should* run automatically, and leave note in the github PR page to that effect).  Once the tests have finished, they will tell you if the fix really does cure the bug.  If it does, merge it and say thank you.  If it doesn't, ask your neighbor to try updating their fix with the feedback from Travis...\n",
    "\n",
    "*Hint: it may be late in the day, but keep being nice!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Problem: Test-driven development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test-driven development is a radically different approach to designing code from what we're generally used to.  In test-driven design, you write the tests *first*.  That is, you write how you expect your code to behave before writing the code.\n",
    "\n",
    "For this problem, try experimenting with test-driven desgin.  Choose a problem (ideally from your science interests) where you know some clear cases that you could write tests for.  Write the full testing suite (using the techniques you developed above).  Then run the tests to ensure all the new ones are  failing due to lack of implementation, and then write the new code.  A few ideas are given below, but, again, for a real challenge try to come up with your own problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the location of Lagrange points for two arbitrary mass bodies.  (Good test cases are the Earth-Moon or Earth-Sun system, which you can probably find on wikipedia.)  Consider solving the problem numerically instead of with formulae you can look up, but use the formulae to concoct the test cases.\n",
    "* Use a clustering algorithm in scikit-learn to identify the centers of two 2D gaussian point-clouds.  The tests are particularly easy in this case because you know the right answer at the outset."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
